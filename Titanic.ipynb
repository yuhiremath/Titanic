{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom statistics import mean\ndataset = pd.read_csv('../input/train.csv')\ntest_dataset = pd.read_csv(\"../input/test.csv\")\n#check for nan values in dataset\nprint('Checking for NULLs in train dataset')\nfor item in dataset.keys():\n    print(\"Nan in \",item,\" is \", dataset[item].isna().sum())\n    \nprint('\\nChecking for NULLs in test dataset')\nfor item in test_dataset.keys():\n    print(\"Nan in \",item,\" is \", test_dataset[item].isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b96c430fa6c98e71f6bb45c2e1f3ab89a6b2cf6"},"cell_type":"code","source":"#assigning mean values of age for both male and female\nage_gender = dataset[['Age', 'Sex']].dropna()\nmale_age_mean = mean(age_gender[age_gender['Sex'] == 'male']['Age'])\nfemale_age_mean = mean(age_gender[age_gender['Sex'] == 'female']['Age'])\ndataset.loc[(dataset['Sex']=='female') & (dataset['Age'].isna()), 'Age'] = female_age_mean\ndataset.loc[(dataset['Sex']=='male') & (dataset['Age'].isna()), 'Age'] = male_age_mean\ntest_dataset.loc[(dataset['Sex']=='female') & (test_dataset['Age'].isna()), 'Age'] = female_age_mean\ntest_dataset.loc[(dataset['Sex']=='male') & (test_dataset['Age'].isna()), 'Age'] = male_age_mean\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a063e6c40e348e003874531d896528229b14b815"},"cell_type":"code","source":"#filling missing values of fare\ntest_dataset['Fare'].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da038b580ca87d5fe94057671b221c9446e1274a"},"cell_type":"code","source":"#filling missing values of embarked\nfor item in dataset.loc[(dataset['Embarked'].isna()), 'Fare']:\n    if item > 50:\n        dataset.loc[(dataset['Embarked'].isna()), 'Embarked'] = 'S'\n    elif item > 25:\n        dataset.loc[(dataset['Embarked'].isna()), 'Embarked'] = 'C'\n    else:\n        dataset.loc[(dataset['Embarked'].isna()), 'Embarked'] = 'Q'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b038c0808cbf4bb9e90431d0bbef99925770f558"},"cell_type":"code","source":"#checking for null values again ignoring cabin\nprint('Checking for NULLs in train dataset')\nfor item in dataset.keys():\n    print(\"Nan in \",item,\" is \", dataset[item].isna().sum())\n    \nprint('\\nChecking for NULLs in test dataset')\nfor item in test_dataset.keys():\n    print(\"Nan in \",item,\" is \", test_dataset[item].isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01f30a7f5e07c7d8f740bd01878e0395792aa485"},"cell_type":"code","source":"#dropping columns that are not so significant\ndataset.drop(columns = ['Cabin','PassengerId'], inplace = True)\ntest_dataset.drop(columns = ['Cabin', 'PassengerId'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6b6e52e943f0a60e716b043dbd5ee8f7ea6ca51"},"cell_type":"code","source":"#Label Encoder on Sex\nfrom sklearn.preprocessing import LabelEncoder\nsex_encoder = LabelEncoder().fit(dataset['Sex'])\ndataset['Sex'] = sex_encoder.transform(dataset['Sex'])\ntest_dataset['Sex'] = sex_encoder.transform(test_dataset['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"173f039624a6443cd48a6849b1620625a66e80e7"},"cell_type":"code","source":"#Label Encoder on Embarked\nembarked_encoder = LabelEncoder().fit(dataset['Embarked'])\ndataset['Embarked'] = embarked_encoder.transform(dataset['Embarked'])\ntest_dataset['Embarked'] = embarked_encoder.transform(test_dataset['Embarked'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17b4b87f1c895e6604ee5ffad73fd33e5f58a893","scrolled":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ef73da065d4052aa35f2099daffa60d82aabe11"},"cell_type":"code","source":"#collecting name titles\n\nimport numpy as np\ndef get_titles(n):\n    names = np.array(n.apply(lambda x : x.split(',')).tolist())[:,1]\n    names = [item.split(' ')[1] for item in names]\n    return pd.Series(names)\ndataset['Name_title'] = get_titles(dataset['Name'])\ndataset.drop(columns=['Name'], inplace = True)\ntest_dataset['Name_title'] = get_titles(test_dataset['Name'])\ntest_dataset.drop(columns=['Name'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cf8cadd7b537b11810c92efd1f84b96d74a6827"},"cell_type":"code","source":"#encoding the name titles\n\nprint(dataset['Name_title'].value_counts())\nprint(test_dataset['Name_title'].value_counts())\n\nname_survived = dataset.groupby(['Name_title'])['Survived'].mean()\nname_survived_encoding = {}\nfor item in name_survived.index:\n    if name_survived[item] == 0:\n        name_survived_encoding[item] = 0\n    elif name_survived[item] < 0.5:\n        name_survived_encoding[item] = 1\n    elif name_survived[item] == 1:\n        name_survived_encoding[item] = 4\n    elif name_survived[item] > 0.5:\n        name_survived_encoding[item] = 3\n    elif name_survived[item] == 0.5:\n        name_survived_encoding[item] = 2\n        \n#Dona. not present in train dataset lets assume that its 0\nfor item in test_dataset['Name_title'].value_counts().index:\n    if(item[0] == 'D' and item[1] == 'o'):\n        name_survived_encoding[item] = 0\n\nname_encoded_train = [name_survived_encoding[item] for item in dataset['Name_title']]\nname_encoded_test = [name_survived_encoding[item] for item in test_dataset['Name_title']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4a75325109abeda8fa6957517cd0b9654e72579"},"cell_type":"code","source":"#keeping the name_titles saved\nName_titles_train = dataset['Name_title']\nName_titles_test = test_dataset['Name_title']\n\n#replacing name_title in dataset with encoding\ndataset['Name_title'] = name_encoded_train\ntest_dataset['Name_title'] = name_encoded_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22796986ef441cdb651cbc252e1d49ef6d00514a"},"cell_type":"code","source":"#extracting features from tickets\nimport numpy as np\nticket_list_train = np.array(dataset['Ticket'].tolist())\nticket_list_test = np.array(test_dataset['Ticket'].tolist())\n\n#generating first letter of the ticket\nticket_list_letter_train = [item[0] for item in ticket_list_train]\nticket_list_letter_test = [item[0] for item in ticket_list_test]\n\n#if the first character is changing to Na\nfor a,item in enumerate(ticket_list_letter_train):\n    if(item.isdigit()):\n        ticket_list_letter_train[a] = 'Na'\nfor a,item in enumerate(ticket_list_letter_test):\n    if(item.isdigit()):\n        ticket_list_letter_test[a] = 'Na'\n\n#hot encoding the ticket\nticket_encoder = LabelEncoder().fit(ticket_list_letter_train)\nticket_encoded_train = ticket_encoder.transform(ticket_list_letter_train)\nticket_encoded_test = ticket_encoder.transform(ticket_list_letter_test)\n\n#keeping the original tickets\nTickets_train = dataset['Ticket']\nTickets_test = test_dataset['Ticket']\n\ndataset['Ticket'] = ticket_encoded_train\ntest_dataset['Ticket'] = ticket_encoded_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f03cb3f8df69cd912e30d1cf0ef74c58975c855d"},"cell_type":"code","source":"#family count \n\ndataset['Family_count'] = dataset['SibSp'] + dataset['Parch']\ntest_dataset['Family_count'] = test_dataset['SibSp'] + test_dataset['Parch']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e4c2647bfda266fd2116e6986cd43b28f333b32"},"cell_type":"code","source":"#Scaling the data\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndrop_tables = ['Survived', 'SibSp']\ntrain_data = dataset.drop(drop_tables, axis = 1)\ntarget = dataset['Survived']\nscaler.fit(dataset.drop(drop_tables, axis = 1))\ntrain_transformed = scaler.transform(dataset.drop(drop_tables, axis = 1))\ntest_transformed = scaler.transform(test_dataset.drop(['SibSp'], axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"082e87efeb65ceb8b89d7443a9c9f648ff819a9c"},"cell_type":"code","source":"#sclaing test_train_data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(train_data, target)\nscaler = StandardScaler().fit(X_train)\nX_train_transformed = scaler.transform(X_train)\nX_test_transformed = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34907e99a0b286296a28957e866bddb6b3a2b711"},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nkfolds = 5\nbest_score = 0\nbest_gamma = 0\nbest_c = 0\nfor c in [1, 10, 100, 200, 300]:\n    for g in [0.01, 0.1, 1, 10]:\n        model = SVC(kernel = 'rbf', gamma = g, C = c)\n        scores = cross_val_score(model, X_train_transformed, Y_train, cv = kfolds)\n        scores = np.mean(scores)\n        if scores > best_score:\n            best_score = scores\n            best_gamma = g\n            best_c = c\nprint(\"SVC gamma = \", best_gamma, \" c = \", best_c)\nbest_model = SVC(kernel = 'rbf', gamma = best_gamma, C = best_c).fit(X_train_transformed, Y_train)\nprint(\"Accuracy by SVC is \", best_model.score(X_test_transformed, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e19b6d3350011892ed7af3fbe627df0594f8a2e"},"cell_type":"code","source":"test_original = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdc3d945d7165a3ab59b30b88c6c234217be3489"},"cell_type":"code","source":"svc_model = SVC(kernel = 'rbf', gamma=best_gamma, C = best_c).fit(train_transformed, target)\ny_predict = svc_model.predict(test_transformed)\nfinal_df = pd.DataFrame(test_original['PassengerId'], columns=['PassengerId'])\nfinal_df['Survived'] = y_predict\nfinal_df.to_csv('final_output_svm_dec4.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffdab23974d2bf89c043865a772f898ead65fa50"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"742d0002b751227d4fa62bc67be86202ef3e9e8e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}